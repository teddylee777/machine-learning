{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryxF5RiKUqxx"
   },
   "source": [
    "# 경사하강법 (Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj8r5IFZUqxx"
   },
   "source": [
    "기본 개념은 함수의 기울기(경사)를 구하여 기울기가 낮은 쪽으로 계속 이동시켜서 극값에 이를 때까지 반복시키는 것입니다.\n",
    "\n",
    "**비용 함수 (Cost Function 혹은 Loss Function)를 최소화**하기 위해 반복해서 파라미터를 업데이트 해 나가는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7mltdDGUqxy"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# 경고 메시지 출력 표기 생략\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Image(url='https://img.pngio.com/scikit-learn-batch-gradient-descent-versus-stochastic-gradient-descent-png-592_319.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRuLBqohLMsY"
   },
   "source": [
    "## 샘플에 활용할 데이터 셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzZRFqeZUqx9"
   },
   "outputs": [],
   "source": [
    "def make_linear(w=0.5, b=0.8, size=50, noise=1.0):\n",
    "    x = np.random.rand(size)\n",
    "    y = w * x + b\n",
    "    noise = np.random.uniform(-abs(noise), abs(noise), size=y.shape)\n",
    "    yy = y + noise\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(x, y, color='r', label=f'y = {w}x + {b}')\n",
    "    plt.scatter(x, yy, label='data')\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.show()\n",
    "    print(f'w: {w}, b: {b}')\n",
    "    return x, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qcmWy8JUqx_",
    "outputId": "5d86f4f4-2666-4f49-c817-0bd93cdc5c27"
   },
   "outputs": [],
   "source": [
    "x, y = make_linear(w=0.3, b=0.5, size=100, noise=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM-u7na_LMsf"
   },
   "source": [
    "## 초기값 (Initializer)과 y_hat (예측, prediction) 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tauo0pixUqyC"
   },
   "source": [
    "w, b 값에 대하여 random한 초기 값을 설정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-_dJXtfpYGB"
   },
   "outputs": [],
   "source": [
    "w = np.random.uniform(low=0.0, high=1.0)\n",
    "b = np.random.uniform(low=0.0, high=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuTVUI03UqyE"
   },
   "source": [
    "`y_hat`은 `prediction`은 값 입니다. 즉, 가설함수에서 실제 값 (y)를 뺀 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trVygK4GLMsg"
   },
   "outputs": [],
   "source": [
    "# 코드를 입력해 주세요\n",
    "y_hat = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4N6MK4elLMsi"
   },
   "source": [
    "## 오차(Error) 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r19eta8MLMsj"
   },
   "source": [
    "Loss Function 혹은 Cost Function을 정의 합니다.\n",
    "\n",
    "Loss (Cost) Function은 예측값인 `y_hat`과 `y`의 차이에 **제곱의 평균**으로 정의합니다.\n",
    "\n",
    "제곱은 오차에 대한 음수 값을 허용하지 않으며, 이는 **Mean Squared Error(MSE)**인 평균 제곱 오차 평가 지표와 관련 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygZPHM2xLMsj"
   },
   "outputs": [],
   "source": [
    "# 코드를 입력해 주세요\n",
    "error = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwzjytZvUqyI"
   },
   "source": [
    "## 학습률 (Learning Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9t_hsbBUUqyJ",
    "outputId": "919848c4-1d3d-40d8-9b09-3076c2b7b1f6"
   },
   "outputs": [],
   "source": [
    "Image(url='https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/images/lr1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJMFH9wTUqyL"
   },
   "source": [
    "한 번 학습할 때 **얼마만큼 가중치(weight)를 업데이트** 해야 하는지 학습 양을 의미합니다.\n",
    "\n",
    "너무 큰 학습률 (Learning Rate)은 가중치 갱신이 크게 되어 **자칫 Error가 수렴하지 못하고 발산**할 수 있으며,\n",
    "\n",
    "너무 작은 학습률은 가중치 갱신이 작게 되어 **가중치 갱신이 충분히 되지 않고, 학습이 끝나** 버릴 수 있습니다. 즉 과소 적합되어 있는 상태로 남아 있을 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajAr6o76LMsm"
   },
   "source": [
    "## Gradient Descent 구현 (단항식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iIYNKTyLMsm"
   },
   "outputs": [],
   "source": [
    "# 최대 반복 횟수\n",
    "num_epoch = 500\n",
    "\n",
    "# 학습율 (learning_rate)\n",
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "IpQ6BcuMLMso",
    "outputId": "5104e999-8161-4c04-b505-b2891551bc08"
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "# random 한 값으로 w, b를 초기화 합니다.\n",
    "w = np.random.uniform(low=0.0, high=1.0)\n",
    "b = np.random.uniform(low=0.0, high=1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    # 코드를 입력해 주세요\n",
    "    y_hat = \n",
    "\n",
    "    # 코드를 입력해 주세요\n",
    "    error = \n",
    "    if error < 0.00005:\n",
    "        break\n",
    "\n",
    "    # 코드를 입력해 주세요\n",
    "    w = \n",
    "    b = \n",
    "    \n",
    "    errors.append(error)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n",
    "    \n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2} w = {1:.1f}, b = {2:.1f} error = {3:.5f}\".format(epoch, w, b, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZnRP06EUqyP"
   },
   "source": [
    "**시각화**\n",
    "\n",
    "학습 진행(epoch)에 따른 오차를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "IblSaamPLMss",
    "outputId": "ae67a5de-d62a-47a4-ff34-ff7c027e3cf0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8iw7WZNpR_I"
   },
   "source": [
    "## 다항식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpgsozbDUqyR"
   },
   "source": [
    "**샘플 데이터**를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAdOEqXCUqyR"
   },
   "source": [
    "이번에는 Feature Data, 즉 X 값이 여러 개인 다항식의 경우에 대해서도 구해보도록 하겠습니다.\n",
    "\n",
    "다항식에서는 X의 갯수 만큼, W 갯수도 늘어날 것입니다.\n",
    "\n",
    "다만, bias (b)의 계수는 1개인 점에 유의해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woNtXYodpSFm"
   },
   "outputs": [],
   "source": [
    "x1 = np.random.rand(100)\n",
    "x2 = np.random.rand(100)\n",
    "x3 = np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsWfNXITvMWt"
   },
   "source": [
    "**다항식을 정의**합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aNdmIf8pvJ6"
   },
   "outputs": [],
   "source": [
    "y = 0.3 * x1 + 0.5 * x2 + 0.7 * x3 + 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgLRY_MoUqyW"
   },
   "source": [
    "## Gradient Descent 구현 (다항식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "Z5IuMfOMqAWq",
    "outputId": "c74b6d9f-b1b6-4799-8e85-df352c06b9a4"
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "w1_grad = []\n",
    "w2_grad = []\n",
    "w3_grad = []\n",
    "\n",
    "num_epoch=5000\n",
    "learning_rate=0.5\n",
    "\n",
    "w1 = np.random.uniform(low=0.0, high=1.0)\n",
    "w2 = np.random.uniform(low=0.0, high=1.0)\n",
    "w3 = np.random.uniform(low=0.0, high=1.0)\n",
    "\n",
    "b = np.random.uniform(low=0.0, high=1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    # 코드를 입력해 주세요\n",
    "    y_hat = \n",
    "\n",
    "    # 코드를 입력해 주세요\n",
    "    error = \n",
    "    if error < 0.00001:\n",
    "        break\n",
    "\n",
    "    # 코드를 입력해 주세요\n",
    "    # 미분값 적용 (Gradient)\n",
    "    w1 = \n",
    "    w2 = \n",
    "    w3 = \n",
    "\n",
    "    b = \n",
    "    \n",
    "    w1_grad.append(w1)\n",
    "    w2_grad.append(w2)\n",
    "    w3_grad.append(w3)\n",
    "    \n",
    "    errors.append(error)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"{0:2} w1 = {1:.5f}, w2 = {2:.5f}, w3 = {3:.5f}, b = {4:.5f} error = {5:.5f}\".format(epoch, w1, w2, w3, b, error))\n",
    "    \n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2} w1 = {1:.1f}, w2 = {2:.1f}, w3 = {3:.1f}, b = {4:.1f} error = {5:.5f}\".format(epoch, w1, w2, w3, b, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "BoIzU-K-qbWZ",
    "outputId": "0a134894-a722-498a-c6e5-375d7e1eb883"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(errors)\n",
    "plt.title('Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq85a7Asw5ZG"
   },
   "source": [
    "## 가중치 (W1, W2, W3) 값들의 변화량 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcDPnN3JUqyb"
   },
   "source": [
    "`Epoch`가 지남에 따라 어떻게 가중치들이 업데이트 되는지 시각화 해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "n4vdXxMcwQaq",
    "outputId": "68acf6dd-9ab7-4941-c3f7-4602ce66ec48"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.hlines(y=0.3, xmin=0, xmax=len(w1_grad), color='r')\n",
    "plt.plot(w1_grad, color='g')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('W1', fontsize=16)\n",
    "plt.legend(['W1 Change', 'W1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "YL1YMw8xwfO2",
    "outputId": "1526dc81-3daa-40a5-fb01-978f4c8eadc6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.hlines(y=0.5, xmin=0, xmax=len(w2_grad), color='r')\n",
    "plt.plot(w2_grad, color='g')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('W2', fontsize=16)\n",
    "plt.legend(['W2 Change', 'W2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "AIJgOedAx1E1",
    "outputId": "14601e42-0ee6-41ea-fce2-357fa3bcc942"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.hlines(y=0.7, xmin=0, xmax=len(w3_grad), color='r')\n",
    "plt.plot(w3_grad, color='g')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('W3', fontsize=16)\n",
    "plt.legend(['W3 Change', 'W3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mEjCh_IUqyh"
   },
   "source": [
    "## 경사하강법을 활용한 SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZUcxfFEUqyi"
   },
   "source": [
    "[SGDRegressor 도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bp1hwmHeUqyi"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YQfFzrYx8hF"
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor(max_iter=5000, tol=1e-5, learning_rate='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZgbofT0Uqyl"
   },
   "outputs": [],
   "source": [
    "x1 = x1.reshape(-1, 1)\n",
    "x2 = x2.reshape(-1, 1)\n",
    "x3 = x3.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEwQH_SFUqym"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([x1, x2, x3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hcz3sL6zUqyo",
    "outputId": "822b9a78-6e51-499e-c1b1-03e9db8b3fa9"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUM8oLfCUqyq",
    "outputId": "7ae9689d-3627-4d05-abdf-a68c008207ab"
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LG5ghAuBUqyu",
    "outputId": "dfa5487c-22c5-4b59-b5f9-6ef8c512ec7b"
   },
   "outputs": [],
   "source": [
    "print(\"w1 = {:.1f}, w2 = {:.1f}, w3 = {:.1f}, b = {:.1f}\".format(model.coef_[0], model.coef_[1], model.coef_[2], model.intercept_[0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02-경사하강법-(Gradient-Descent)-(실습)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
